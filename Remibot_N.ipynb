{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from nltk.stem import wordnet\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "import pyttsx3\n",
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_con():\n",
    "    url = \"http://www.google.com\"\n",
    "    timeout = 4\n",
    "    try:\n",
    "        request = requests.get(url, timeout=timeout)\n",
    "        return True\n",
    "    except(requests.ConnectionError, requests.Timeout) as exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak_output(text2):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(text2)\n",
    "    print(text2)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source: \n",
    "        print(\"Listening...\")\n",
    "        audio = r.listen(source)   \n",
    "        voice_data = \" \"\n",
    "        try:\n",
    "            voice_data = r.recognize_google(audio)\n",
    "            print(voice_data)\n",
    "        except:\n",
    "            print(\"I did not get that.\")\n",
    "        return voice_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization(text):\n",
    "    text=str(text).lower()\n",
    "    special_char_text=re.sub(r'[^a-z]',' ',text)\n",
    "    tokenized_text=nltk.word_tokenize(special_char_text)\n",
    "    lemmatized_text=wordnet.WordNetLemmatizer()\n",
    "    tags_list=pos_tag(tokenized_text,tagset=None)\n",
    "    lema_words=[]\n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'):\n",
    "            pos_val='v'\n",
    "        elif pos_token.startswith('J'):\n",
    "            pos_val='a'\n",
    "        elif pos_token.startswith('R'):\n",
    "            pos_val='r'\n",
    "        else:\n",
    "            pos_val='n'\n",
    "        lema_token=lemmatized_text.lemmatize(token,pos_val)\n",
    "        lema_words.append(lema_token)\n",
    "        \n",
    "    return \" \".join(lema_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting_of_Input(u_input):\n",
    "    global b\n",
    "    q=[]\n",
    "    a=u_input.split()\n",
    "    for i in a:\n",
    "        if i in stop:\n",
    "            continue\n",
    "        else:\n",
    "            q.append(i)\n",
    "        \n",
    "        b=\" \".join(q)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Greeting_Inputs = [\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\", \"hey\", \"hai\", \"hallo\"]\n",
    "Greeting_Responses = [\"Hi. I will assist you.\", \"Hey. I will assist you.\", \"*nods*\", \"Hi there. I will assist you.\", \"Hello. I will assist you.\", \"I am glad you are talking to me. I will assist you.\"]\n",
    "def greeting(sentence):\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in Greeting_Inputs:\n",
    "            return random.choice(Greeting_Responses)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"remibot_dataset_1614271001.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Error downloading 'stopwords' from\n",
      "[nltk_data]     <https://raw.githubusercontent.com/nltk/nltk_data/gh-\n",
      "[nltk_data]     pages/packages/corpora/stopwords.zip>:   <urlopen\n",
      "[nltk_data]     error [SSL: CERTIFICATE_VERIFY_FAILED] certificate\n",
      "[nltk_data]     verify failed: self-signed certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['lemmatized_symptoms']=df['Symptom'].apply(text_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')\n",
    "stop_words = ['?',',','.','!','(',')']\n",
    "for i in stop_words:\n",
    "    stop.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_f():\n",
    "    global tfidf\n",
    "    global df_tfidf\n",
    "    cv=CountVectorizer()\n",
    "    x=cv.fit_transform(df['lemmatized_symptoms']).toarray()\n",
    "\n",
    "    features=cv.get_feature_names()\n",
    "    df_bow=pd.DataFrame(x,columns=features)\n",
    "\n",
    "    splitting_of_Input(ques)\n",
    "        \n",
    "    ques_lema=text_normalization(b)\n",
    "    ques_bow=cv.transform([ques_lema]).toarray() \n",
    "       \n",
    "    tfidf=TfidfVectorizer()\n",
    "    x_tfidf=tfidf.fit_transform(df['lemmatized_symptoms']).toarray()\n",
    "    \n",
    "    df_tfidf=pd.DataFrame(x_tfidf,columns=tfidf.get_feature_names())\n",
    "    ques_tfidf=tfidf.transform([ques_lema]).toarray()\n",
    "\n",
    "    cosine_value=1-pairwise_distances(df_bow,ques_bow,metric='cosine')\n",
    "    index_value=cosine_value.argmax()\n",
    "    if ques != \"bye\":\n",
    "        if greeting(ques) != None:\n",
    "            speak_output(f\"Remibot: {greeting(ques)}\")\n",
    "        else:\n",
    "            for k in chat_tfidf(ques):\n",
    "                var_n = (f\"The Natural Remedies for the following Symptoms are:\\n {k}\")  \n",
    "            print(\"Remibot: \", end=\" \")\n",
    "            speak_output(var_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_tfidf(text):\n",
    "    lemma=text_normalization(text)\n",
    "    tf=tfidf.transform([lemma]).toarray()\n",
    "    cos=1-pairwise_distances(df_tfidf,tf,metric='cosine')\n",
    "    index_value=cos.argmax()\n",
    "    return [df['Remedies'].loc[index_value]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_offline():\n",
    "    speak_output(\"Please type, as speech service is down due to internet connectivity.\")\n",
    "    while continue_diag == True:\n",
    "        user_input = input(\"User:\")\n",
    "        ques = user_input.lower()\n",
    "        if ques == \"bye\":\n",
    "            break\n",
    "        else:\n",
    "            if ques == \"thanks\" or ques == \"thank you\" or ques == \"thank you so much\" or ques == \"thank you very much\":\n",
    "                speak_output(\"Remibot: Most Welcome\")\n",
    "                break\n",
    "        main_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pyttsx3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m continue_diag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m speak_output(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello I am Remibot! You can talk with me to find Natural Remedies about certain symptoms.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m net_con() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m, in \u001b[0;36mspeak_output\u001b[1;34m(text2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspeak_output\u001b[39m(text2):\n\u001b[1;32m----> 2\u001b[0m     engine \u001b[38;5;241m=\u001b[39m pyttsx3\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m      3\u001b[0m     engine\u001b[38;5;241m.\u001b[39msay(text2)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text2)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyttsx3' is not defined"
     ]
    }
   ],
   "source": [
    "continue_diag = True\n",
    "print(\"\", end = \" \")\n",
    "speak_output(\"Hello I am Remibot! You can talk with me to find Natural Remedies about certain symptoms.\")\n",
    "while True:\n",
    "    if net_con() == True:\n",
    "         while continue_diag == True:\n",
    "            ques = record_audio()\n",
    "            if ques == \"bye\":\n",
    "                break\n",
    "            else:\n",
    "                if ques == \"thanks\" or ques == \"thank you\" or ques == \"thank you so much\" or ques == \"thank you very much\":\n",
    "                    speak_output(\"Most Welcome\")\n",
    "                    break\n",
    "            if net_con == False:\n",
    "                for_offline()\n",
    "            main_f()\n",
    "            if net_con == False:\n",
    "                for_offline()\n",
    "    if net_con() == False:\n",
    "        for_offline()\n",
    "        \n",
    "    speak_output(\"Bye. Take care...\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out=open('Remibot_N','wb')\n",
    "pickle.dump(speak_output,pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.Recognizer"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
